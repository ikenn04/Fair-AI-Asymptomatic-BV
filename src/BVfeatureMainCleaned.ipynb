{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317d5d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import io\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "import seaborn as sns   \n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.feature_selection import SelectKBest, SelectPercentile, f_classif\n",
    "from tabulate import tabulate\n",
    "from sklearn.metrics import precision_score, average_precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_recall_curve, roc_auc_score\n",
    "from scipy import stats\n",
    "from sklearn import metrics\n",
    "from utils import fairness_metrics\n",
    "#from EXPERIMENTS_WITH_PROBS import plot_PR_curve\n",
    "import os\n",
    "import warnings\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df44b4dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###\n",
    "warnings.filterwarnings(action='once')\n",
    "url = \"https://cdn.jsdelivr.net/gh/ramenfeast/BV-ethnicity-report/BV%20Dataset%20copy.csv\"\n",
    "download = requests.get(url).content\n",
    "df = pd.read_csv(io.StringIO(download.decode('utf-8')))\n",
    "\n",
    "#%%Clean data for all\n",
    "df = df.drop([394,395,396], axis = 0)\n",
    "df.loc[df['Nugent score'] <7, 'Nugent score'] = 0\n",
    "df.loc[df['Nugent score'] >=7, 'Nugent score'] = 1\n",
    "\n",
    "df['pH']=df['pH']/14\n",
    "\n",
    "#all ethnic\n",
    "dfall = df\n",
    "#dfall=dfall.drop(labels= ['Ethnic Groupa', 'Community groupc '], axis=1)\n",
    "dfall=dfall.drop(labels= ['Community groupc '], axis=1)\n",
    "dfall.iloc[:,1:-1]=dfall.iloc[:,1:-1]/100\n",
    "Xall = dfall.iloc[:,:-1]\n",
    "yall = dfall.iloc[:,-1]\n",
    "\n",
    "#print(df.shape)\n",
    "#X_trainall, X_testall, y_trainall, y_testall = train_test_split(Xall, yall,test_size=0.2)\n",
    "\n",
    "#white dataframe\n",
    "dfwhite = df[df[\"Ethnic Groupa\"] == 'White'] \n",
    "#dfwhite =dfwhite.drop(labels= ['Ethnic Groupa', 'Community groupc '], axis=1)\n",
    "dfwhite =dfwhite.drop(labels= ['Community groupc '], axis=1)\n",
    "dfwhite.iloc[:,1:-1]=dfwhite.iloc[:,1:-1]/100\n",
    "Xwhite = dfwhite.iloc[:,:-1]\n",
    "ywhite = dfwhite.iloc[:,-1]\n",
    "\n",
    "#X_trainwhite, X_testwhite, y_trainwhite, y_testwhite = train_test_split(Xwhite, ywhite,test_size=0.2)\n",
    "\n",
    "#blackdataframe\n",
    "dfblack = df[df[\"Ethnic Groupa\"] == 'Black']\n",
    "#dfblack=dfblack.drop(labels= ['Ethnic Groupa', 'Community groupc '], axis=1)\n",
    "dfblack=dfblack.drop(labels= ['Community groupc '], axis=1)\n",
    "dfblack.iloc[:,1:-1]=dfblack.iloc[:,1:-1]/100\n",
    "Xblack = dfblack.iloc[:,:-1]\n",
    "yblack = dfblack.iloc[:,-1]\n",
    "\n",
    "#X_trainblack, X_testblack, y_trainblack, y_testblack = train_test_split(Xblack, yblack,test_size=0.2)\n",
    "\n",
    "#asian dataframe\n",
    "dfasian = df[df[\"Ethnic Groupa\"] == 'Asian']\n",
    "#dfasian=dfasian.drop(labels= ['Ethnic Groupa', 'Community groupc '], axis=1)\n",
    "dfasian=dfasian.drop(labels= ['Community groupc '], axis=1)\n",
    "dfasian.iloc[:,1:-1]=dfasian.iloc[:,1:-1]/100\n",
    "Xasian = dfasian.iloc[:,:-1]\n",
    "yasian = dfasian.iloc[:,-1]\n",
    "\n",
    "#X_trainasian, X_testasian, y_trainasian, y_testasian = train_test_split(Xasian, yasian,test_size=0.2)\n",
    "\n",
    "#hispanic dataframe\n",
    "dfhispanic = df[df[\"Ethnic Groupa\"] == 'Hispanic']\n",
    "#dfhispanic=dfhispanic.drop(labels= ['Ethnic Groupa', 'Community groupc '], axis=1)\n",
    "dfhispanic=dfhispanic.drop(labels= ['Community groupc '], axis=1)\n",
    "dfhispanic.iloc[:,1:-1]=dfhispanic.iloc[:,1:-1]/100\n",
    "Xhispanic = dfhispanic.iloc[:,:-1]\n",
    "yhispanic = dfhispanic.iloc[:,-1]\n",
    "\n",
    "#X_trainhispanic, X_testhispanic, y_trainhispanic, y_testhispanic = train_test_split(Xhispanic, yhispanic,test_size=0.2)\n",
    "\n",
    "#creating dictionary of accuracy scores\n",
    "feataccdict = {\"All features all ethnicities accuracy\": [], \"All features white only accuracy\": [], \n",
    "               \"All features black only accuracy\": [], \"All features asian only accuracy\": [], \n",
    "               \"All features hispanic only accuracy\":[], \"Ftest all ethnicities accuracy\": [], \"Ftest white only accuracy\": [], \n",
    "               \"Ftest black only accuracy\": [], \"Ftest asian only accuracy\": [], \n",
    "               \"Ftest hispanic only accuracy\":[], \"Sig features all ethnicities accuracy\": [], \"Sig features white only accuracy\": [], \n",
    "                  \"Sig features black only accuracy\": [], \"Sig features asian only accuracy\": [], \n",
    "                  \"Sig features hispanic only accuracy\":[], \"Corr features all ethnicities accuracy\": [], \"Corr features white only accuracy\": [], \n",
    "               \"Corr features black only accuracy\": [], \"Corr features asian only accuracy\": [], \n",
    "               \"Corr features hispanic only accuracy\":[], \"Ttest features all ethnicities accuracy\": [], \"Ttest features white only accuracy\": [], \n",
    "                \"Ttest features black only accuracy\": [], \"Ttest features asian only accuracy\": [], \n",
    "                \"Ttest features hispanic only accuracy\":[], \"Gini features all ethnicities accuracy\": [], \"Gini features white only accuracy\": [], \n",
    "               \"Gini features black only accuracy\": [], \"Gini features asian only accuracy\": [], \n",
    "               \"Gini features hispanic only accuracy\":[]}\n",
    "\n",
    "fprdict = {}\n",
    "tprdict = {}\n",
    "aucdict = {}\n",
    "\n",
    "dfalltandf = pd.DataFrame(columns=['Features', 'Feature Test', 'Value'])\n",
    "bestauc = 0\n",
    "\n",
    "#deletes fairness metric csv\n",
    "proballfeat = 'prob_allfeatures.csv'\n",
    "probftest = 'prob_ftest.csv'\n",
    "probttest = 'prob_ttest.csv'\n",
    "probsigpb = 'prob_sigpb.csv'\n",
    "probcorrpb = 'prob_corrpb.csv'\n",
    "probgini = 'prob_gini.csv'\n",
    "\n",
    "files_to_delete = [proballfeat, probftest, probttest, probsigpb, probcorrpb, probgini]\n",
    "\n",
    "# Loop over the list of files and delete each one\n",
    "for file in files_to_delete:\n",
    "  try:\n",
    "    os.remove(file)\n",
    "    print(file, \"deleted\")\n",
    "  except:\n",
    "    print(file, \"not found\")\n",
    "\n",
    "prcurvedirectory = \"PRcurves\"\n",
    "try:\n",
    "    shutil.rmtree(prcurvedirectory)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Directory {prcurvedirectory} not found\")\n",
    "try:\n",
    "    os.mkdir(prcurvedirectory)\n",
    "except FileExistsError:\n",
    "    print(f\"Directory {prcurvedirectory} already exists\")\n",
    "\n",
    "\n",
    "fairnessfile = 'fairness_metric_data.csv'\n",
    "try:\n",
    "  os.remove(fairnessfile)\n",
    "  print(fairnessfile,\"deleted\")\n",
    "except:\n",
    "  print(fairnessfile, \"not found\")\n",
    "\n",
    "auccombinedfile = 'Feature_auc_combined.csv'\n",
    "try:\n",
    "  os.remove(auccombinedfile)\n",
    "  print(\"file deleted\")\n",
    "except:\n",
    "  print(\"file not found\")\n",
    "\n",
    "fprtprcombinedfile = 'Feature_fpr_tpr_combined.csv'\n",
    "try:\n",
    "  os.remove(fprtprcombinedfile)\n",
    "  print(\"file deleted\")\n",
    "except:\n",
    "  print(\"file not found\")\n",
    "\n",
    "#tpr and fpr directory for each model and set\n",
    "tprfprdirectory = \"Feature_tpr_fpr\"\n",
    "try:\n",
    "    shutil.rmtree(tprfprdirectory)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Directory {tprfprdirectory} not found\")\n",
    "\n",
    "try:\n",
    "    os.mkdir(tprfprdirectory)\n",
    "except FileExistsError:\n",
    "    print(f\"Directory {tprfprdirectory} already exists\")\n",
    "\n",
    "#feature set directories\n",
    "featsetdirectory = \"Feature_Sets\"\n",
    "try:\n",
    "    shutil.rmtree(featsetdirectory)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Directory {featsetdirectory} not found\")\n",
    "\n",
    "try:\n",
    "    os.mkdir(featsetdirectory)\n",
    "except FileExistsError:\n",
    "    print(f\"Directory {featsetdirectory} already exists\")\n",
    "\n",
    "#aucdirectory\n",
    "aucdirectory = \"Feature_auc\"\n",
    "try:\n",
    "    shutil.rmtree(aucdirectory)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Directory {aucdirectory} not found\")\n",
    "\n",
    "try:\n",
    "    os.mkdir(aucdirectory)\n",
    "except FileExistsError:\n",
    "    print(f\"Directory {aucdirectory} already exists\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bd92fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RFtrain_test_1(px,py,featset, dictionary, testname, efeatset, modeltype='Random Forest'):\n",
    "    global bestauc\n",
    "    bestauc = 0\n",
    "    acclist = []\n",
    "    preclist =[]\n",
    "    reclist = []\n",
    "    f1list =[]\n",
    "    fprlist = []\n",
    "    tprlist = []\n",
    "    auclist = []\n",
    "    \n",
    "    #repeat RF runs 10 times\n",
    "    for x in range(10):\n",
    "        pxtrain, pxtest, pytrain, pytest = train_test_split(px,py,test_size=0.2,random_state = x)\n",
    "        \n",
    "        #take ethnic group out of pxtrain\n",
    "        dfethxtrain = pxtrain[\"Ethnic Groupa\"]\n",
    "\n",
    "        dfethxtest = pxtest[\"Ethnic Groupa\"]\n",
    "\n",
    "        arrayethxtest = dfethxtest.to_numpy()\n",
    "        #print(arrayethxtest)\n",
    "        \n",
    "        pxtrain = pxtrain.drop(labels= [\"Ethnic Groupa\"], axis=1)\n",
    "        pxtest = pxtest.drop(labels= [\"Ethnic Groupa\"], axis=1)\n",
    "\n",
    "        #print(type(pytest))\n",
    "\n",
    "        if modeltype == 'Logistic Regression':\n",
    "            clf = LogisticRegression()\n",
    "            clf.fit(pxtrain, pytrain)\n",
    "            y_pred = clf.predict(pxtest)\n",
    "        elif modeltype == 'SVM':\n",
    "            clf = SVC(probability=True)\n",
    "            clf.fit(pxtrain, pytrain)\n",
    "            y_pred = clf.predict(pxtest)\n",
    "        else:\n",
    "            clf = RandomForestClassifier(n_estimators = 100)\n",
    "            clf.fit(pxtrain, pytrain)\n",
    "            y_pred = clf.predict(pxtest)\n",
    "\n",
    "        acclist.append(accuracy_score(pytest,y_pred))\n",
    "        preclist.append(precision_score(pytest,y_pred))\n",
    "        reclist.append(recall_score(pytest,y_pred))\n",
    "        f1list.append(f1_score(pytest,y_pred))\n",
    "\n",
    "        ytestarray = pytest.to_numpy()\n",
    "        #print(type(y_pred))\n",
    "        #print(type(y_pred))\n",
    "        #print(type(arrayethxtest))\n",
    "\n",
    "        #do fairness metric and save to csv\n",
    "        dffairreturn = fairness_metrics(ytestarray, y_pred, arrayethxtest)\n",
    "        dffairreturn.insert(loc=0, column= 'Model_Type_with_Feature_Set', value= modeltype+'_'+featset)\n",
    "\n",
    "        pred_probs = clf.predict_proba(pxtest)[:,1]\n",
    "        predictions = y_pred >= 0.5\n",
    "        dffairreturn[\"AUC\"] = roc_auc_score(pytest, pred_probs)\n",
    "        dffairreturn[\"f1\"]= f1_score(pytest,predictions)\n",
    "        dffairreturn[\"precision\"] = precision_score(pytest,predictions)\n",
    "        dffairreturn[\"recall\"] = recall_score(pytest,predictions)\n",
    "        dffairreturn[\"AP\"] = average_precision_score(pytest, pred_probs)\n",
    "\n",
    "        for race in [\"Asian\", \"Black\", \"Hispanic\", \"White\"]:\n",
    "            dffairreturn[f\"AP {race}\"] = average_precision_score(pytest[arrayethxtest==race],pred_probs[arrayethxtest==race])\n",
    "    \n",
    "\n",
    "\n",
    "        #display(dffairreturn)\n",
    "        if not os.path.isfile(fairnessfile):\n",
    "            dffairreturn.to_csv(fairnessfile, index=False)\n",
    "        else:\n",
    "            dffairreturn.to_csv(fairnessfile, mode='a', index=False, header=False)\n",
    "            \n",
    "        prdf = pd.DataFrame()\n",
    "        prdf['y_true'] = pytest\n",
    "        prdf['probs'] = pred_probs\n",
    "        prdf['fold'] = x\n",
    "        prdf['run'] = x\n",
    "        prdf['Race'] = efeatset\n",
    "\n",
    "\n",
    "        prcurvedata = ''\n",
    "        if modeltype == 'SVM':\n",
    "            if testname == 'allfeatures':\n",
    "                prcurvedata = proballfeat\n",
    "            elif testname == 'ftest':\n",
    "                prcurvedata = probftest\n",
    "            elif testname == 'ttest':\n",
    "                prcurvedata = probttest\n",
    "            elif testname == 'pbsig':\n",
    "                prcurvedata = probsigpb\n",
    "            elif testname == 'pbcorr':\n",
    "                prcurvedata = probcorrpb\n",
    "            elif testname == 'gini':\n",
    "                prcurvedata = probgini\n",
    "            print('prcurvedata ', prcurvedata)\n",
    "\n",
    "            if not os.path.isfile(prcurvedata):\n",
    "                prdf.to_csv(prcurvedata , index=False)\n",
    "            else:\n",
    "                prdf.to_csv(prcurvedata , mode='a', index=False, header=False)\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        fpr, tpr, threshold = metrics.roc_curve(pytest, pred_probs)\n",
    "        auc = metrics.roc_auc_score(pytest, pred_probs)\n",
    "        auclist.append(auc)\n",
    "\n",
    "        #pytest is ytrue\n",
    "\n",
    "        #plot_PR_curve(pytest, pred_probs, 'Precisionrecallcurvedata.csv')\n",
    "\n",
    "\n",
    "        #print(tpr)\n",
    "        #print(fpr)\n",
    "        #print(auc)\n",
    "        \n",
    "        if auc > bestauc:\n",
    "            fprdict[modeltype+'_'+featset+' fpr'] = fpr\n",
    "            tprdict[modeltype+'_'+featset+' tpr'] = tpr\n",
    "            aucdict[modeltype+'_'+featset+ ' auc'] = auc\n",
    "            bestauc = auc\n",
    "        #print(auc)\n",
    "    \n",
    "    #print(tprdict)\n",
    "    #print(fprdict)\n",
    "\n",
    "    \n",
    "    #printing out results the mean of 10 runs for each metric   \n",
    "    arr = np.array(acclist)\n",
    "    arrmean = np.mean(arr)\n",
    "    print(modeltype, featset,' RF acc average =', arrmean)\n",
    "    precarr = np.array(preclist)\n",
    "    precarrmean = np.mean(precarr)\n",
    "    print(modeltype, featset,' Precision RF average =', precarrmean)\n",
    "    recarr = np.array(reclist)\n",
    "    recarrmean = np.mean(recarr)\n",
    "    print(modeltype, featset,' Recall RF average =', recarrmean)\n",
    "    f1arr = np.array(f1list)\n",
    "    f1arrmean = np.mean(f1arr)\n",
    "    print(modeltype, featset,' F1 score RF average =', f1arrmean)\n",
    "    print('Training dataset count:', pxtrain.shape[0])\n",
    "    print('Test dataset count:', pxtest.shape[0])\n",
    "    \n",
    "    \n",
    "    aucarr = np.array(auclist)\n",
    "    aucmean = np.mean(aucarr)\n",
    "    #aucmeandict[featset+' auc'] = aucmean\n",
    "\n",
    "    \n",
    "    #return featset, auc, fpr, tpr\n",
    "\n",
    "    #create ROC curve\n",
    "    bestfpr = fprdict[modeltype+'_'+featset+' fpr']\n",
    "    besttpr = tprdict[modeltype+'_'+featset+' tpr']\n",
    "    bestauc = aucdict[modeltype+'_'+featset+ ' auc']\n",
    "\n",
    "    #print(bestauc)\n",
    "    #print(aucdict)\n",
    "\n",
    "\n",
    "    dftpr = pd.DataFrame({'Best TPR': besttpr})\n",
    "    dffpr = pd.DataFrame({'Best FPR': bestfpr})\n",
    "    dftprfpr = pd.concat([dffpr['Best FPR'], dftpr['Best TPR']], axis=1)\n",
    "\n",
    "    #display(dftpr)\n",
    "    #display(dffpr)\n",
    "    #display(dftprfpr)\n",
    "\n",
    "    dftprfpr.to_csv(tprfprdirectory+'/'+modeltype+'_'+featset+'tprfpr.csv', index=False)\n",
    "\n",
    "    #csv for combined fprtpr\n",
    "    dftprfpr.insert(loc=0, column= 'Model_Type_with_Feature_Set', value= modeltype+'_'+featset)\n",
    "    if not os.path.isfile(fprtprcombinedfile):\n",
    "        dftprfpr.to_csv(fprtprcombinedfile, index=False)\n",
    "    else:\n",
    "        dftprfpr.to_csv(fprtprcombinedfile, mode='a', index=False, header=False)\n",
    "\n",
    "    #individual csv for bestauc and combined auc\n",
    "    pd.DataFrame([bestauc]).to_csv(aucdirectory+'/'+modeltype+'_'+featset+' auc.csv', index=False, header=['Best AUC'])\n",
    "    dfauc = pd.DataFrame({'Best AUC': [bestauc]})\n",
    "    dfauc.insert(loc=0, column= 'Model_Type_with_Feature_Set', value= modeltype+'_'+featset)\n",
    "    if not os.path.isfile(auccombinedfile):\n",
    "        dfauc.to_csv(auccombinedfile, index=False)\n",
    "    else:\n",
    "        dfauc.to_csv(auccombinedfile, mode='a', index=False, header=False)\n",
    "\n",
    "    plt.title(str(modeltype)+'_'+'Receiver Operator Curve for:' +str(featset))\n",
    "    plt.plot(bestfpr,besttpr,label=\"auc=\"+str(aucdict[modeltype+'_'+featset+' auc']))\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()\n",
    "\n",
    "    #metrics.plot_roc_curve(clfrf, pxtest, pytest) \n",
    "    \n",
    "    #attach accuracy list to each key in dictionary\n",
    "    if dictionary == 'feataccdict' and featset == 'All features': \n",
    "        feataccdict[\"All features all ethnicities accuracy\"] = acclist\n",
    "    if dictionary == 'feataccdict' and featset == 'All features White': \n",
    "        feataccdict[\"All features white only accuracy\"] = acclist\n",
    "    if dictionary == 'feataccdict' and featset == 'All features Black': \n",
    "        feataccdict[\"All features black only accuracy\"] = acclist\n",
    "    if dictionary == 'feataccdict' and featset == 'All features Asian': \n",
    "        feataccdict[\"All features asian only accuracy\"] = acclist\n",
    "    if dictionary == 'feataccdict' and featset == 'All features Hispanic': \n",
    "        feataccdict[\"All features hispanic only accuracy\"] = acclist\n",
    "        \n",
    "    if dictionary == 'feataccdict' and featset == 'Ftest features with all ethnicities': \n",
    "        feataccdict[\"Ftest all ethnicities accuracy\"] = acclist\n",
    "    if dictionary == 'feataccdict' and featset == 'Ftest features with only white': \n",
    "        feataccdict[\"Ftest white only accuracy\"] = acclist\n",
    "    if dictionary == 'feataccdict' and featset == 'Ftest features with only black': \n",
    "        feataccdict[\"Ftest black only accuracy\"] = acclist\n",
    "    if dictionary == 'feataccdict' and featset == 'Ftest features with only asian': \n",
    "        feataccdict[\"Ftest asian only accuracy\"] = acclist\n",
    "    if dictionary == 'feataccdict' and featset == 'Ftest features with only hispanic': \n",
    "        feataccdict[\"Ftest hispanic only accuracy\"] = acclist\n",
    "        \n",
    "    if dictionary == 'feataccdict' and featset == 'Correlated PBtest features with all ethnicities': \n",
    "        feataccdict[\"Corr features all ethnicities accuracy\"] = acclist\n",
    "    if dictionary == 'feataccdict' and featset == 'Correlated PBtest features with white only': \n",
    "        feataccdict[\"Corr features white only accuracy\"] = acclist\n",
    "    if dictionary == 'feataccdict' and featset == 'Correlated PBtest features with black only': \n",
    "        feataccdict[\"Corr features black only accuracy\"] = acclist\n",
    "    if dictionary == 'feataccdict' and featset == 'Correlated PBtest features with asian only': \n",
    "        feataccdict[\"Corr features asian only accuracy\"] = acclist\n",
    "    if dictionary == 'feataccdict' and featset == 'Correlated PBtest features with hispanic only': \n",
    "        feataccdict[\"Corr features hispanic only accuracy\"] = acclist\n",
    "    \n",
    "    if dictionary == 'feataccdict' and featset == 'Significant PBtest features with all ethnicities': \n",
    "        feataccdict[\"Sig features all ethnicities accuracy\"] = acclist\n",
    "    if dictionary == 'feataccdict' and featset == 'Significant PBtest features with white only': \n",
    "        feataccdict[\"Sig features white only accuracy\"] = acclist\n",
    "    if dictionary == 'feataccdict' and featset == 'Significant PBtest features with black only': \n",
    "        feataccdict[\"Sig features black only accuracy\"] = acclist\n",
    "    if dictionary == 'feataccdict' and featset == 'Significant PBtest features with asian only': \n",
    "        feataccdict[\"Sig features asian only accuracy\"] = acclist\n",
    "    if dictionary == 'feataccdict' and featset == 'Significant PBtest features with hispanic only': \n",
    "        feataccdict[\"Sig features hispanic only accuracy\"] = acclist\n",
    "        \n",
    "        \n",
    "    if dictionary == 'feataccdict' and featset == 'Ttest features with all ethnicities': \n",
    "        feataccdict[\"Ttest features all ethnicities accuracy\"] = acclist\n",
    "    if dictionary == 'feataccdict' and featset == 'Ttest features with white only': \n",
    "        feataccdict[\"Ttest features white only accuracy\"] = acclist\n",
    "    if dictionary == 'feataccdict' and featset == 'Ttest features with black only': \n",
    "        feataccdict[\"Ttest features black only accuracy\"] = acclist\n",
    "    if dictionary == 'feataccdict' and featset == 'Ttest features with asian only': \n",
    "        feataccdict[\"Ttest features asian only accuracy\"] = acclist\n",
    "    if dictionary == 'feataccdict' and featset == 'Ttest features with hispanic only': \n",
    "        feataccdict[\"Ttest features hispanic only accuracy\"] = acclist\n",
    "        \n",
    "        \n",
    "    if dictionary == 'feataccdict' and featset == 'Gini features with all ethnicities': \n",
    "        feataccdict[\"Gini features all ethnicities accuracy\"] = acclist\n",
    "    if dictionary == 'feataccdict' and featset == 'Gini features with only white': \n",
    "        feataccdict[\"Gini features white only accuracy\"] = acclist\n",
    "    if dictionary == 'feataccdict' and featset == 'Gini features with only black': \n",
    "        feataccdict[\"Gini features black only accuracy\"] = acclist\n",
    "    if dictionary == 'feataccdict' and featset == 'Gini features with only asian': \n",
    "        feataccdict[\"Gini features asian only accuracy\"] = acclist\n",
    "    if dictionary == 'feataccdict' and featset == 'Gini features with only hispanic': \n",
    "        feataccdict[\"Gini features hispanic only accuracy\"] = acclist\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742e58ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Test all features all ethnicities\n",
    "featset = RFtrain_test_1(Xall,yall, 'All features','feataccdict', 'allfeatures', 'All ethnicities')\n",
    "print()\n",
    "#Test normal white only\n",
    "#display(y_testwhite)\n",
    "'''\n",
    "RFtrain_test_1(Xwhite,ywhite, 'All features White', 'feataccdict')\n",
    "print()\n",
    "#Test normal black only\n",
    "RFtrain_test_1(Xblack,yblack, 'All features Black','feataccdict')\n",
    "print()\n",
    "##Test normal asian only\n",
    "RFtrain_test_1(Xasian,yasian, 'All features Asian','feataccdict')\n",
    "print()\n",
    "#Test normal hispanic only\n",
    "RFtrain_test_1(Xhispanic,yhispanic, 'All features Hispanic','feataccdict')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1c7627",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression\n",
    "#Test all features all ethnicities\n",
    "featset = RFtrain_test_1(Xall,yall, 'All features', 'feataccdict', 'allfeatures', 'All features', 'Logistic Regression')\n",
    "print()\n",
    "#Test normal white only\n",
    "#display(y_testwhite)\n",
    "'''\n",
    "RFtrain_test_1(Xwhite,ywhite, 'All features White', 'feataccdict', 'Logistic Regression')\n",
    "print()\n",
    "#Test normal black only\n",
    "RFtrain_test_1(Xblack,yblack, 'All features Black','feataccdict','Logistic Regression')\n",
    "print()\n",
    "##Test normal asian only\n",
    "RFtrain_test_1(Xasian,yasian, 'All features Asian','feataccdict', 'Logistic Regression')\n",
    "print()\n",
    "#Test normal hispanic only\n",
    "RFtrain_test_1(Xhispanic,yhispanic, 'All features Hispanic','feataccdict', 'Logistic Regression')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f8b1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM\n",
    "#Test all features all ethnicities\n",
    "featset = RFtrain_test_1(Xall,yall, 'All features', 'feataccdict', 'allfeatures','All ethnicities', 'SVM')\n",
    "print()\n",
    "#Test normal white only\n",
    "#display(y_testwhite)\n",
    "'''\n",
    "RFtrain_test_1(Xwhite,ywhite, 'All features White', 'feataccdict', 'SVM')\n",
    "print()\n",
    "#Test normal black only\n",
    "RFtrain_test_1(Xblack,yblack, 'All features Black','feataccdict', 'SVM')\n",
    "print()\n",
    "##Test normal asian only\n",
    "RFtrain_test_1(Xasian,yasian, 'All features Asian','feataccdict', 'SVM')\n",
    "print()\n",
    "#Test normal hispanic only\n",
    "RFtrain_test_1(Xhispanic,yhispanic, 'All features Hispanic','feataccdict', 'SVM')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced6be3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create ROC curve for RF all feat\n",
    "\n",
    "plt.figure(0).clf()\n",
    "plt.plot(fprdict['Random Forest_All features fpr'],tprdict['Random Forest_All features tpr'],label=\"All ethnicities auc=\"+str(aucdict['Random Forest_All features auc']),linestyle='solid')\n",
    "'''\n",
    "plt.plot(fprdict['Random Forest_All features White fpr'],tprdict['Random Forest_All features White tpr'],label=\"White auc=\"+str(aucdict['Random Forest_All features White auc']), linestyle='dotted')\n",
    "plt.plot(fprdict['Random Forest_All features Black fpr'],tprdict['Random Forest_All features Black tpr'],label=\"Black auc=\"+str(aucdict['Random Forest_All features Black auc']),linestyle='dashdot')\n",
    "plt.plot(fprdict['Random Forest_All features Asian fpr'],tprdict['Random Forest_All features Asian tpr'],label=\"Asian auc=\"+str(aucdict['Random Forest_All features Asian auc']),linestyle='dashed')\n",
    "plt.plot(fprdict['Random Forest_All features Hispanic fpr'],tprdict['Random Forest_All features Hispanic tpr'],label=\"Hispanic auc=\"+str(aucdict['Random Forest_All features Hispanic auc']),linestyle='dotted')\n",
    "'''\n",
    "\n",
    "plt.title('Receiver Operator Curve for:' +str('All Features'))\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.legend(loc = 'lower right')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc96c59b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#turning dictionary into dataframe and then making boxplot\n",
    "alleth = pd.DataFrame(dict([ (k,pd.Series(v)) for k,v in feataccdict.items() ]))\n",
    "allfeatdf = alleth[[\"All features all ethnicities accuracy\",\"All features white only accuracy\", \"All features black only accuracy\", \"All features asian only accuracy\", \"All features hispanic only accuracy\"]]\n",
    "#display(alleth)\n",
    "display(allfeatdf)\n",
    "\n",
    "fig = sns.boxplot(data=allfeatdf)\n",
    "sns.set(rc={'figure.figsize':(100,50)})\n",
    "sns.set(font_scale=4)\n",
    "plt.xlabel(\"All features\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy with all features\")\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3aa6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ftest feature test so compares population variances and finds significant differences#\n",
    "def Bestftest_1(px,py,featset, xall, yall, efeatset, model = 'Random Forest'):\n",
    "    global dfalltandf\n",
    "    \n",
    "    fvalue_Best = SelectKBest(f_classif, k=50)\n",
    "\n",
    "    #7-10 stores ethnic and drops it before fit\n",
    "    dfethx = xall[\"Ethnic Groupa\"]\n",
    "    xall = xall.drop(labels= [\"Ethnic Groupa\"], axis=1)\n",
    "    px = px.drop(labels= [\"Ethnic Groupa\"], axis=1)\n",
    "\n",
    "    fvalue_Best.fit(px, py)\n",
    "    scores = fvalue_Best.scores_\n",
    "    \n",
    "    #created new train and test sets\n",
    "    cols = fvalue_Best.get_support(indices=True)\n",
    "    #print(cols)\n",
    "    #display(xall)\n",
    "    #display(px)\n",
    "\n",
    "    features_df_newx = xall.iloc[:,cols]\n",
    "    \n",
    "    #add ethnic group back on\n",
    "    #features_df_newx[\"Ethnic Groupa\"] = dfethx\n",
    "\n",
    "    #display(features_df_newx)\n",
    "\n",
    "    \n",
    "    #table of features with fvalue\n",
    "    dfimpfeatfval = pd.DataFrame(columns = ['Feature Name', 'F-score'])\n",
    "    for (index, colname) in enumerate(features_df_newx):\n",
    "        dfimpfeatfval = dfimpfeatfval.append({'Feature Name': colname, 'F-score': scores[index]}, ignore_index=True)\n",
    "        dfimpfeatfval = dfimpfeatfval.sort_values(by = ['F-score'], ascending = False)\n",
    "    with pd.option_context('display.max_rows', None,\n",
    "                       'display.max_columns', None,\n",
    "                       'display.precision', 3,\n",
    "                       ):\n",
    "\n",
    "        display(dfimpfeatfval)\n",
    "    \n",
    "    gname = dfimpfeatfval['Feature Name']\n",
    "    gval = dfimpfeatfval['F-score']\n",
    "    \n",
    "    dfftest = dfimpfeatfval[['Feature Name']].copy()\n",
    "    dfftest.rename(columns={'Feature Name': 'Features'}, inplace=True)\n",
    "    \n",
    "    dfftesttemp = dfftest\n",
    "    \n",
    "    #display(dfftest)\n",
    "    \n",
    "    dfftesttemp['Feature Test'] = featset\n",
    "    dfftesttemp['Value'] = 1\n",
    "    \n",
    "    dfalltandf = dfalltandf[dfalltandf['Feature Test'] != featset]\n",
    "    \n",
    "    dfalltandf = pd.concat([dfalltandf, dfftesttemp])\n",
    "    #display(dfalltandf)\n",
    "\n",
    "    dfimpfeatfval.to_csv(featsetdirectory+'/'+featset+\".csv\", index=False)\n",
    "    \n",
    "    #sns.set(rc={'figure.figsize':(100,50)})\n",
    "    #sns.set(font_scale=4)\n",
    "    #sns.barplot(x = gval, y = gname)\n",
    "    \n",
    "    features_df_newx['Ethnic Groupa'] = dfethx\n",
    "    \n",
    "    display(features_df_newx)\n",
    "    if model == 'Logistic Regression':\n",
    "        RFtrain_test_1(features_df_newx, yall, featset,'feataccdict', 'ftest', efeatset, model)\n",
    "    elif model == 'SVM':\n",
    "        RFtrain_test_1(features_df_newx, yall, featset,'feataccdict', 'ftest', efeatset, model)\n",
    "    elif model == 'Random Forest':\n",
    "        RFtrain_test_1(features_df_newx, yall, featset,'feataccdict', 'ftest', efeatset)\n",
    "    return gname,gval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e606970c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Ftest all ethnicities, RF\n",
    "#Bestftest(X_trainall, X_testall, y_trainall, y_testall, 'Ftest features with all ethnicities')\n",
    "gname, gval = Bestftest_1(Xall,yall, 'Ftest features with all ethnicities',Xall, yall, 'All ethnicities')\n",
    "sns.set(rc={'figure.figsize':(100,50)})\n",
    "sns.set(font_scale=4)\n",
    "sns.barplot(x = gval, y = gname)\n",
    "display(dfalltandf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d931f61",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Test Ftest white only RF\n",
    "gname, gval = Bestftest_1(Xwhite, ywhite, 'Ftest features with only white',Xall, yall, 'White')\n",
    "sns.set(rc={'figure.figsize':(100,50)})\n",
    "sns.set(font_scale=4)\n",
    "sns.barplot(x = gval, y = gname)\n",
    "display(dfalltandf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc61631a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Ftest black only RF\n",
    "gname, gval = Bestftest_1(Xblack,yblack,'Ftest features with only black', Xall, yall, 'Black')\n",
    "sns.set(rc={'figure.figsize':(100,50)})\n",
    "sns.set(font_scale=4)\n",
    "sns.barplot(x = gval, y = gname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eab35ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Ftest asian only RF\n",
    "gname, gval =Bestftest_1(Xasian,yasian,'Ftest features with only asian', Xall, yall, 'Asian')\n",
    "sns.set(rc={'figure.figsize':(100,50)})\n",
    "sns.set(font_scale=4)\n",
    "sns.barplot(x = gval, y = gname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2519abde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Ftest hispanic only RF\n",
    "gname, gval =Bestftest_1(Xhispanic,yhispanic,'Ftest features with only hispanic', Xall, yall, 'Hispanic')\n",
    "sns.set(rc={'figure.figsize':(100,50)})\n",
    "sns.set(font_scale=4)\n",
    "sns.barplot(x = gval, y = gname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15688297",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create ROC curve for RF Ftest\n",
    "\n",
    "plt.figure(0).clf()\n",
    "plt.plot(fprdict['Random Forest_Ftest features with all ethnicities fpr'],tprdict['Random Forest_Ftest features with all ethnicities tpr'],label=\"All ethnicities features auc=\"+str(aucdict['Random Forest_Ftest features with all ethnicities auc']),linestyle='solid')\n",
    "plt.plot(fprdict['Random Forest_Ftest features with only white fpr'],tprdict['Random Forest_Ftest features with only white tpr'],label=\"White features auc=\"+str(aucdict['Random Forest_Ftest features with only white auc']), linestyle='dotted')\n",
    "plt.plot(fprdict['Random Forest_Ftest features with only black fpr'],tprdict['Random Forest_Ftest features with only black tpr'],label=\"Black features auc=\"+str(aucdict['Random Forest_Ftest features with only black auc']),linestyle='dashdot')\n",
    "plt.plot(fprdict['Random Forest_Ftest features with only asian fpr'],tprdict['Random Forest_Ftest features with only asian tpr'],label=\"Asian features auc=\"+str(aucdict['Random Forest_Ftest features with only asian auc']),linestyle='dashed')\n",
    "plt.plot(fprdict['Random Forest_Ftest features with only hispanic fpr'],tprdict['Random Forest_Ftest features with only hispanic tpr'],label=\"Hispanic features auc=\"+str(aucdict['Random Forest_Ftest features with only hispanic auc']),linestyle='dotted')\n",
    "\n",
    "plt.title('Receiver Operator Curve for:' +str('All Features'))\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.legend(loc = 'lower right')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8959b6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LR\n",
    "Bestftest_1(Xall,yall,'Ftest features with all ethnicities', Xall, yall,'All ethnicities', 'Logistic Regression')\n",
    "Bestftest_1(Xwhite,ywhite,'Ftest features with only white', Xall, yall,'White','Logistic Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3738bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bestftest_1(Xblack,yblack,'Ftest features with only black', Xall, yall,'Black', 'Logistic Regression')\n",
    "Bestftest_1(Xasian,yasian,'Ftest features with only asian', Xall, yall,'Asian','Logistic Regression')\n",
    "Bestftest_1(Xhispanic,yhispanic,'Ftest features with only hispanic', Xall, yall,'Hispanic','Logistic Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6808db6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM\n",
    "Bestftest_1(Xall,yall,'Ftest features with all ethnicities', Xall, yall,'All ethnicities','SVM')\n",
    "Bestftest_1(Xwhite,ywhite,'Ftest features with only white', Xall, yall,'White','SVM')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cef5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bestftest_1(Xblack,yblack,'Ftest features with only black', Xall, yall,'Black','SVM')\n",
    "Bestftest_1(Xasian,yasian,'Ftest features with only asian', Xall, yall,'Asian','SVM')\n",
    "Bestftest_1(Xhispanic,yhispanic,'Ftest features with only hispanic', Xall, yall,'Hispanic','SVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334531bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pivot table\n",
    "table = pd.pivot_table(dfalltandf, values='Value', index=['Feature Test'],\n",
    "                    columns=['Features'], aggfunc=np.sum, fill_value=0)\n",
    "display(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc311a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating boxplot\n",
    "alleth = pd.DataFrame(dict([ (k,pd.Series(v)) for k,v in feataccdict.items() ]))\n",
    "ftdf = alleth[[\"Ftest all ethnicities accuracy\",\"Ftest white only accuracy\", \"Ftest black only accuracy\", \"Ftest asian only accuracy\", \"Ftest hispanic only accuracy\"]]\n",
    "display(ftdf)\n",
    "display(alleth)\n",
    "\n",
    "fig = sns.boxplot(data=ftdf)\n",
    "sns.set(rc={'figure.figsize':(100,50)})\n",
    "sns.set(font_scale=4)\n",
    "plt.xlabel(\"All features\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Ftest Accuracy\")\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8af5dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlation test between a binary variable and a continuous variable\n",
    "def BestPB_1(px,py,featset,sigfeatset,xall,yall, efeatset, model = 'Random Forest'):\n",
    "    from scipy import stats\n",
    "    global dfalltandf\n",
    "    #pointbiserial\n",
    "    #used when one variable is interval and other variable has only 2 possible variables\n",
    "    significantlist = []\n",
    "    correlationlist = []\n",
    "    dfimpfeatsig = pd.DataFrame(columns = ['Feature Name', 'P-value'])\n",
    "    dfimpfeatcorr = pd.DataFrame(columns = ['Feature Name', 'Correlation Coefficient'])\n",
    "\n",
    "    #7-10 stores ethnic and drops it before fit\n",
    "    dfethx = px[\"Ethnic Groupa\"]\n",
    "    px = px.drop(labels= [\"Ethnic Groupa\"], axis=1)\n",
    "\n",
    "    \n",
    "    for (columnName, X_trainfeature) in px.iteritems():\n",
    "        #point biserial \n",
    "        correlation_value,p_value= stats.pointbiserialr(X_trainfeature, py)\n",
    "        \n",
    "\n",
    "        alpha = 0.2\n",
    "        #restricted p value by alpha\n",
    "        if p_value < alpha:\n",
    "            significantlist.append(columnName)\n",
    "            dfimpfeatsig = dfimpfeatsig.append({'Feature Name': columnName, 'P-value': p_value}, ignore_index=True)\n",
    "            #if between .5 and 1 is strongly correlated\n",
    "            #further restricted by correlation value\n",
    "            if correlation_value > 0.5: \n",
    "                correlationlist.append(columnName)\n",
    "                dfimpfeatcorr = dfimpfeatcorr.append({'Feature Name': columnName, 'Correlation Coefficient': correlation_value}, ignore_index=True)\n",
    "    dfimpfeatsig = dfimpfeatsig.sort_values(by = ['P-value'], ascending = True)\n",
    "    dfimpfeatcorr = dfimpfeatcorr.sort_values(by = ['Correlation Coefficient'], ascending = False)\n",
    "\n",
    "    with pd.option_context('display.max_rows', None,\n",
    "                       'display.max_columns', None,\n",
    "                       'display.precision', 3,\n",
    "                       ):\n",
    "\n",
    "        display(dfimpfeatsig)\n",
    "        display(dfimpfeatcorr)\n",
    "    \n",
    "    \n",
    "    gnames = dfimpfeatsig['Feature Name']\n",
    "    gvals = dfimpfeatsig['P-value']\n",
    "    gnamec = dfimpfeatcorr['Feature Name']\n",
    "    gvalc = dfimpfeatcorr['Correlation Coefficient']\n",
    "    \n",
    "    \n",
    "    dfsig = dfimpfeatsig[['Feature Name']].copy()\n",
    "    dfcorr = dfimpfeatcorr[['Feature Name']].copy()\n",
    "    \n",
    "    dfsig.rename(columns={'Feature Name': 'Features'}, inplace=True)\n",
    "    dfcorr.rename(columns={'Feature Name': 'Features'}, inplace=True)\n",
    "    \n",
    "    dfsigtemp = dfsig\n",
    "    dfcorrtemp = dfcorr\n",
    "    \n",
    "    #display(dfftest)\n",
    "    \n",
    "    dfsigtemp['Feature Test'] = sigfeatset\n",
    "    dfsigtemp['Value'] = 1\n",
    "    \n",
    "    dfcorrtemp['Feature Test'] = featset\n",
    "    dfcorrtemp['Value'] = 1\n",
    "    \n",
    "    dfalltandf = dfalltandf[dfalltandf['Feature Test'] != featset]\n",
    "    dfalltandf = dfalltandf[dfalltandf['Feature Test'] != sigfeatset]\n",
    "    \n",
    "    dfalltandf = pd.concat([dfalltandf, dfsigtemp])\n",
    "    dfalltandf = pd.concat([dfalltandf, dfcorrtemp])\n",
    "    \n",
    "    dfimpfeatsig.to_csv(featsetdirectory+'/'+sigfeatset+\".csv\", index=False)\n",
    "    dfimpfeatcorr.to_csv(featsetdirectory+'/'+featset+\".csv\", index=False)\n",
    "    \n",
    "    \n",
    "    #significant (only using p value)\n",
    "    significantlist.append(\"Ethnic Groupa\")\n",
    "    px_sig = xall[significantlist]\n",
    "    display(px_sig)\n",
    "    #px_sig[\"Ethnic Groupa\"] = dfethx\n",
    "    if model == 'Logistic Regression':\n",
    "        RFtrain_test_1(px_sig, yall, sigfeatset,'feataccdict', 'pbsig', efeatset, model)\n",
    "    elif model == 'SVM':\n",
    "        RFtrain_test_1(px_sig, yall, sigfeatset,'feataccdict', 'pbsig', efeatset, model)\n",
    "    else:\n",
    "        RFtrain_test_1(px_sig, yall, sigfeatset,'feataccdict', 'pbsig', efeatset)\n",
    "    \n",
    "    #pvalue and correlation value\n",
    "    if gnamec.shape[0] != 0 or gvalc.shape[0] != 0:\n",
    "        correlationlist.append(\"Ethnic Groupa\")\n",
    "        px_corr = xall[correlationlist]\n",
    "        #px_corr[\"Ethnic Groupa\"] = dfethx\n",
    "        #RFtrain_test_1(px_corr, yall, featset, 'feataccdict')\n",
    "        if model == 'Logistic Regression':\n",
    "            RFtrain_test_1(px_corr, yall, featset,'feataccdict','pbcorr',efeatset, model)\n",
    "        elif model == 'SVM':\n",
    "            RFtrain_test_1(px_corr, yall, featset,'feataccdict', 'pbcorr',efeatset, model)\n",
    "        elif model == 'Random Forest':\n",
    "            RFtrain_test_1(px_corr, yall, featset,'feataccdict', 'pbcorr',efeatset)\n",
    "    else:\n",
    "        print(featset, 'has no correlated features')\n",
    "        #return\n",
    "    \n",
    "    #sns.set(rc={'figure.figsize':(100,50)})\n",
    "    #sns.set(font_scale=4)\n",
    "    #cbp = sns.barplot(x = gvalc, y = gnamec)\n",
    "    \n",
    "\n",
    "    return gvalc, gnamec, gvals, gnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910a4500",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Test PB all ethnicities\n",
    "gvals,gnames, gvalc, gnamec = BestPB_1(Xall,yall, 'Correlated PBtest features with all ethnicities', 'Significant PBtest features with all ethnicities', Xall, yall, 'All ethnicities')\n",
    "sns.set(rc={'figure.figsize':(100,80)})\n",
    "sns.set(font_scale=4)\n",
    "plt.title(\"Significant Features with All ethnicities\")\n",
    "sbp = sns.barplot(x = gvalc, y = gnamec)\n",
    "display(dfalltandf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfccc71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(100,50)})\n",
    "sns.set(font_scale=4)\n",
    "plt.title(\"Correlated Features with All ethnicities\")\n",
    "cbp = sns.barplot(x=gvals,y=gnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434a7f83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Test PB white\n",
    "gvals,gnames,gvalc, gnamec = BestPB_1(Xwhite, ywhite, 'Correlated PBtest features with white only','Significant PBtest features with white only', Xall, yall, 'White')\n",
    "sns.set(rc={'figure.figsize':(100,50)})\n",
    "sns.set(font_scale=4)\n",
    "cbp = sns.barplot(x = gvalc, y = gnamec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688991e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(100,50)})\n",
    "sns.set(font_scale=4)\n",
    "plt.title(\"Correlated Features with White only\")\n",
    "cbp = sns.barplot(x=gvals,y=gnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6191283c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test PB black\n",
    "gvals,gnames,gvalc, gnamec = BestPB_1(Xblack, yblack, 'Correlated PBtest features with black only', 'Significant PBtest features with black only', Xall, yall,'Black')\n",
    "sns.set(rc={'figure.figsize':(100,50)})\n",
    "sns.set(font_scale=4)\n",
    "cbp = sns.barplot(x = gvalc, y = gnamec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9292828d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(100,50)})\n",
    "sns.set(font_scale=4)\n",
    "plt.title(\"Correlated Features with Black only\")\n",
    "cbp = sns.barplot(x=gvals,y=gnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f61a489",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Test PB asian\n",
    "gvals,gnames,gvalc, gnamec = BestPB_1(Xasian, yasian, 'Correlated PBtest features with asian only', 'Significant PBtest features with asian only', Xall, yall,'Asian')\n",
    "if gnamec.shape[0] != 0 or gvalc.shape[0] != 0:\n",
    "    sns.set(rc={'figure.figsize':(100,50)})\n",
    "    sns.set(font_scale=4)\n",
    "    cbp = sns.barplot(x = gvalc, y = gnamec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66cb3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if gnames.shape[0] != 0 or gvals.shape[0] != 0:\n",
    "    sns.set(rc={'figure.figsize':(100,50)})\n",
    "    sns.set(font_scale=4)\n",
    "    plt.title(\"Correlated Features with Asian only\")\n",
    "    cbp = sns.barplot(x=gvals,y=gnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f475578a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Test PB hispanic\n",
    "gvals,gnames,gvalc, gnamec = BestPB_1(Xhispanic, yhispanic, 'Correlated PBtest features with hispanic only', 'Significant PBtest features with hispanic only', Xall, yall,'Hispanic')\n",
    "sns.set(rc={'figure.figsize':(100,50)})\n",
    "sns.set(font_scale=4)\n",
    "cbp = sns.barplot(x = gvalc, y = gnamec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f149bb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(100,50)})\n",
    "sns.set(font_scale=4)\n",
    "plt.title(\"Correlated Features with Hispanic only\")\n",
    "cbp = sns.barplot(x=gvals,y=gnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa09b1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "BestPB_1(Xall,yall, 'Correlated PBtest features with all ethnicities', 'Significant PBtest features with all ethnicities', Xall, yall,'All ethnicities','Logistic Regression')\n",
    "BestPB_1(Xwhite, ywhite, 'Correlated PBtest features with white only','Significant PBtest features with white only', Xall, yall,'White','Logistic Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7203ae14",
   "metadata": {},
   "outputs": [],
   "source": [
    "BestPB_1(Xblack, yblack, 'Correlated PBtest features with black only', 'Significant PBtest features with black only', Xall, yall,'Black','Logistic Regression')\n",
    "BestPB_1(Xasian, yasian, 'Correlated PBtest features with asian only', 'Significant PBtest features with asian only', Xall, yall,'Asian','Logistic Regression')\n",
    "BestPB_1(Xhispanic, yhispanic, 'Correlated PBtest features with hispanic only', 'Significant PBtest features with hispanic only', Xall, yall,'Hispanic','Logistic Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703f06f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "BestPB_1(Xall,yall, 'Correlated PBtest features with all ethnicities', 'Significant PBtest features with all ethnicities', Xall, yall,'All ethnicities','SVM')\n",
    "BestPB_1(Xwhite, ywhite, 'Correlated PBtest features with white only','Significant PBtest features with white only', Xall, yall,'White','SVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ed16de",
   "metadata": {},
   "outputs": [],
   "source": [
    "BestPB_1(Xblack, yblack, 'Correlated PBtest features with black only', 'Significant PBtest features with black only', Xall, yall,'Black','SVM')\n",
    "BestPB_1(Xasian, yasian, 'Correlated PBtest features with asian only', 'Significant PBtest features with asian only', Xall, yall,'Asian','SVM')\n",
    "BestPB_1(Xhispanic, yhispanic, 'Correlated PBtest features with hispanic only', 'Significant PBtest features with hispanic only',Xall, yall,'Hispanic','SVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcaa0b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pivot table\n",
    "table = pd.pivot_table(dfalltandf, values='Value', index=['Feature Test'],\n",
    "                    columns=['Features'], aggfunc=np.sum, fill_value=0)\n",
    "display(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f859a204",
   "metadata": {},
   "outputs": [],
   "source": [
    "alleth = pd.DataFrame(dict([ (k,pd.Series(v)) for k,v in feataccdict.items() ]))\n",
    "corrdf = alleth[[\"Corr features all ethnicities accuracy\",\"Corr features white only accuracy\", \"Corr features black only accuracy\", \"Corr features asian only accuracy\", \"Corr features hispanic only accuracy\"]]\n",
    "display(corrdf)\n",
    "display(alleth)\n",
    "\n",
    "fig = sns.boxplot(data=corrdf)\n",
    "sns.set(rc={'figure.figsize':(100,50)})\n",
    "sns.set(font_scale=4)\n",
    "plt.xlabel(\"All features\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Correlated Feature Accuracy\")\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7569ef7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "alleth = pd.DataFrame(dict([ (k,pd.Series(v)) for k,v in feataccdict.items() ]))\n",
    "sigdf = alleth[[\"Sig features all ethnicities accuracy\",\"Sig features white only accuracy\", \"Sig features black only accuracy\", \"Sig features asian only accuracy\", \"Sig features hispanic only accuracy\"]]\n",
    "display(sigdf)\n",
    "display(alleth)\n",
    "\n",
    "fig = sns.boxplot(data=sigdf)\n",
    "sns.set(rc={'figure.figsize':(100,50)})\n",
    "sns.set(font_scale=4)\n",
    "plt.xlabel(\"All features\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Significant Feature Accuracy\")\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15300ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ttest tests for mean between two variables\n",
    "def BestTtest_1(dfethnic, px, py,featset, xall, yall, efeatset,model = 'Random Forest'):\n",
    "    global dfalltandf\n",
    "    \n",
    "     #stores ethnic and drops it before fit\n",
    "    dfeth = dfethnic[\"Ethnic Groupa\"]\n",
    "    dfethnic = dfethnic.drop(labels= [\"Ethnic Groupa\"], axis=1)\n",
    "    \n",
    "    Nugent0 = dfethnic[dfethnic['Nugent score'] == 0]\n",
    "    #print(Nugent0)\n",
    "    Nugent1 = dfethnic[dfethnic['Nugent score'] == 1]\n",
    "    #print(Nugent1)\n",
    "\n",
    "\n",
    "    impfeat =[]\n",
    "    dfimpfeat = pd.DataFrame(columns = ['Feature Name', 'P-value'])\n",
    "    gfeatname = []\n",
    "    for column in Nugent0:\n",
    "        Nugent0data = Nugent0[column]\n",
    "        Nugent1data = Nugent1[column]\n",
    "        tstat, pval = stats.ttest_ind(a = Nugent0data, b = Nugent1data, alternative=\"two-sided\")\n",
    "    \n",
    "        alpha = 0.05\n",
    "        if pval < alpha:\n",
    "            impfeat.append(column)\n",
    "            dfimpfeat = dfimpfeat.append({'Feature Name': column, 'P-value': pval}, ignore_index=True)\n",
    "    dfimpfeat = dfimpfeat.sort_values(by = ['P-value'], ascending = True)\n",
    "    dfimpfeat = dfimpfeat.loc[dfimpfeat[\"Feature Name\"] != 'Nugent score']\n",
    "    with pd.option_context('display.max_rows', None,\n",
    "                           'display.max_columns', None,\n",
    "                           'display.precision', 3,\n",
    "                           ):\n",
    "        display(dfimpfeat)\n",
    "\n",
    "    impfeat.remove('Nugent score')\n",
    "    \n",
    "\n",
    "    #barplot of ttest\n",
    "    gnamet = dfimpfeat['Feature Name']\n",
    "    gvalt = dfimpfeat['P-value']\n",
    "    \n",
    "    dfttest = dfimpfeat[['Feature Name']].copy()\n",
    "    \n",
    "    dfttest.rename(columns={'Feature Name': 'Features'}, inplace=True)\n",
    "    \n",
    "    dfttesttemp = dfttest\n",
    "    \n",
    "    #display(dfftest)\n",
    "    \n",
    "    dfttesttemp['Feature Test'] = featset\n",
    "    dfttesttemp['Value'] = 1\n",
    "    \n",
    "    dfalltandf = dfalltandf[dfalltandf['Feature Test'] != featset]\n",
    "    \n",
    "    dfalltandf = pd.concat([dfalltandf, dfttesttemp])\n",
    "    \n",
    "    dfimpfeat.to_csv(featsetdirectory+'/'+featset+\".csv\", index=False)\n",
    "\n",
    "    #sns.set(rc={'figure.figsize':(100,50)})\n",
    "    #sns.set(font_scale=4)\n",
    "    #cbp = sns.barplot(x = gvalt, y = gnamet)\n",
    "    \n",
    "    impfeat.append(\"Ethnic Groupa\")\n",
    "    px_imp = xall[impfeat]\n",
    "\n",
    "    #display(dfeth)\n",
    "    #display(px_imp)\n",
    "    #RFtrain_test_1(px_imp, yall, featset, 'feataccdict')\n",
    "\n",
    "    if model == 'Logistic Regression':\n",
    "        RFtrain_test_1(px_imp, yall, featset,'feataccdict', 'ttest', efeatset,model)\n",
    "    elif model == 'SVM':\n",
    "        RFtrain_test_1(px_imp, yall, featset,'feataccdict', 'ttest', efeatset,model)\n",
    "    elif model == 'Random Forest':\n",
    "        RFtrain_test_1(px_imp, yall, featset,'feataccdict', 'ttest',efeatset)\n",
    "    \n",
    "    return gvalt, gnamet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa35885",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Ttest all ethnicities\n",
    "gvalt, gnamet = BestTtest_1(dfall,Xall,yall, 'Ttest features with all ethnicities',Xall, yall,'All ethnicities')\n",
    "sns.set(rc={'figure.figsize':(100,50)})\n",
    "sns.set(font_scale=4)\n",
    "cbp = sns.barplot(x = gvalt, y = gnamet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f928e19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Test Ttest white only\n",
    "gvalt, gnamet = BestTtest_1(dfwhite, Xwhite,ywhite, 'Ttest features with white only',Xall, yall, 'White')\n",
    "sns.set(rc={'figure.figsize':(100,50)})\n",
    "sns.set(font_scale=4)\n",
    "cbp = sns.barplot(x = gvalt, y = gnamet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8347a140",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Ttest black only\n",
    "gvalt, gnamet =BestTtest_1(dfblack, Xblack,yblack, 'Ttest features with black only',Xall, yall, 'Black')\n",
    "sns.set(rc={'figure.figsize':(100,50)})\n",
    "sns.set(font_scale=4)\n",
    "cbp = sns.barplot(x = gvalt, y = gnamet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b61712c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Test Ttest asian only\n",
    "gvalt, gnamet =BestTtest_1(dfasian, Xasian,yasian, 'Ttest features with asian only',Xall, yall, 'Asian')\n",
    "sns.set(rc={'figure.figsize':(100,50)})\n",
    "sns.set(font_scale=4)\n",
    "cbp = sns.barplot(x = gvalt, y = gnamet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01175af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Ttest hispanic only\n",
    "gvalt, gnamet = BestTtest_1(dfhispanic, Xhispanic,yhispanic, 'Ttest features with hispanic only',Xall, yall, 'Hispanic')\n",
    "sns.set(rc={'figure.figsize':(100,50)})\n",
    "sns.set(font_scale=4)\n",
    "cbp = sns.barplot(x = gvalt, y = gnamet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52837c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "BestTtest_1(dfall,Xall,yall, 'Ttest features with all ethnicities', Xall, yall, 'All ethnicities', 'Logistic Regression')\n",
    "BestTtest_1(dfwhite, Xwhite,ywhite, 'Ttest features with white only', Xall, yall, 'White','Logistic Regression')\n",
    "BestTtest_1(dfblack, Xblack,yblack, 'Ttest features with black only', Xall, yall, 'Black','Logistic Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee42276",
   "metadata": {},
   "outputs": [],
   "source": [
    "BestTtest_1(dfasian, Xasian,yasian, 'Ttest features with asian only', Xall, yall, 'Asian','Logistic Regression')\n",
    "BestTtest_1(dfhispanic, Xhispanic,yhispanic, 'Ttest features with hispanic only', Xall, yall, 'Hispanic','Logistic Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed91d3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "BestTtest_1(dfall,Xall,yall, 'Ttest features with all ethnicities', Xall, yall, 'All ethnicities','SVM')\n",
    "BestTtest_1(dfwhite, Xwhite,ywhite, 'Ttest features with white only', Xall, yall, 'White','SVM')\n",
    "BestTtest_1(dfblack, Xblack,yblack, 'Ttest features with black only', Xall, yall, 'Black','SVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404f52bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "BestTtest_1(dfasian, Xasian,yasian, 'Ttest features with asian only', Xall, yall, 'Asian','SVM')\n",
    "BestTtest_1(dfhispanic, Xhispanic,yhispanic, 'Ttest features with hispanic only', Xall, yall, 'Hispanic','SVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab18ab95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pivot table\n",
    "table = pd.pivot_table(dfalltandf, values='Value', index=['Feature Test'],\n",
    "                    columns=['Features'], aggfunc=np.sum, fill_value=0)\n",
    "display(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252a05ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "alleth = pd.DataFrame(dict([ (k,pd.Series(v)) for k,v in feataccdict.items() ]))\n",
    "ttestdf = alleth[[\"Ttest features all ethnicities accuracy\",\"Ttest features white only accuracy\", \"Ttest features black only accuracy\", \"Ttest features asian only accuracy\", \"Ttest features hispanic only accuracy\"]]\n",
    "display(ttestdf)\n",
    "display(alleth)\n",
    "\n",
    "fig = sns.boxplot(data=ttestdf)\n",
    "sns.set(rc={'figure.figsize':(100,50)})\n",
    "sns.set(font_scale=4)\n",
    "plt.xlabel(\"All features\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Ttest Feature Accuracy\")\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79840348",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def BestGini_1(px,py,featset,xall,yall,efeatset,model = 'Random Forest'):\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    global dfalltandf\n",
    "    \n",
    "    #calculates gini gain (higher gain more important feature)\n",
    "    clf = DecisionTreeClassifier(criterion='gini')\n",
    "    \n",
    "    #stores ethnic and drops it before fit\n",
    "    dfethx = px[\"Ethnic Groupa\"]\n",
    "    px = px.drop(labels= [\"Ethnic Groupa\"], axis=1)\n",
    "    \n",
    "    # Fit the decision tree classifier\n",
    "    clf = clf.fit(px, py)\n",
    "\n",
    "    # Feature importances based on reduction in Gini impurity each feature gives when splitting nodes!!\n",
    "    feature_importances = clf.feature_importances_\n",
    "    #print(feature_importances)\n",
    " \n",
    "    # Sort the feature importances from greatest to least using the sorted indices\n",
    "    sorted_indices = feature_importances.argsort()[::-1]\n",
    "\n",
    "    #array of names sorted accoridng to index of feature importance\n",
    "    sorted_feature_names = px.columns[sorted_indices]\n",
    "    \n",
    "    sorted_importances = feature_importances[sorted_indices]\n",
    "\n",
    "    new_si = np.delete(sorted_importances, np.where(sorted_importances == 0))\n",
    "    new_si_length = len(new_si)\n",
    "    \n",
    "    sfn_list = sorted_feature_names.tolist()\n",
    "    sfn_list = sfn_list[0:new_si_length]\n",
    "\n",
    "    #get list of only important features from gini\n",
    "    giniimplist = []\n",
    "    for i in range(len(sorted_importances)): \n",
    "        if sorted_importances[i] > 0:\n",
    "            giniimplist.append(sorted_feature_names[i])\n",
    "\n",
    "    for i in range(len(sorted_feature_names)):\n",
    "        print(sorted_feature_names[i].ljust(30)+\":\"+str(sorted_importances[i]))\n",
    "\n",
    "    print\n",
    "    \n",
    "    # Create a bar plot of the feature importances\n",
    "    #sns.set(rc={'figure.figsize':(100,50)})\n",
    "    #sns.set(font_scale=4)\n",
    "    #bp = sns.barplot(x = new_si, y = sfn_list)\n",
    "    \n",
    "    \n",
    "    dfgini = pd.DataFrame (sfn_list, columns = ['Feature Name'])\n",
    "    \n",
    "    \n",
    "    dfgini.rename(columns={'Feature Name': 'Features'}, inplace=True)\n",
    "    #print(dfgini)\n",
    "    \n",
    "    dfginitemp = dfgini\n",
    "    \n",
    "    #display(dfftest)\n",
    "    \n",
    "    dfginitemp['Feature Test'] = featset\n",
    "    dfginitemp['Value'] = 1\n",
    "    \n",
    "    dfalltandf = dfalltandf[dfalltandf['Feature Test'] != featset]\n",
    "    \n",
    "    dfalltandf = pd.concat([dfalltandf, dfginitemp])\n",
    "\n",
    "    silist = new_si.tolist()\n",
    "    dfginicsv = pd.DataFrame(sfn_list, columns = ['Feature Name'])\n",
    "    dfginicsv.insert(1,'Gini score', silist)\n",
    "    #print(dfginicsv)\n",
    "    dfginicsv.to_csv(featsetdirectory+'/'+featset+\".csv\", index=False)\n",
    "    \n",
    "    giniimplist.append(\"Ethnic Groupa\")\n",
    "    px_impg = xall[giniimplist]\n",
    "    #px_impg[\"Ethnic Groupa\"] = dfethx\n",
    "    #RFtrain_test_1(px_impg, yall, featset,'feataccdict')\n",
    "\n",
    "    print(giniimplist)\n",
    "\n",
    "    if model == 'Logistic Regression':\n",
    "        RFtrain_test_1(px_impg, yall, featset,'feataccdict', 'gini', efeatset,model)\n",
    "    elif model == 'SVM':\n",
    "        RFtrain_test_1(px_impg, yall, featset,'feataccdict', 'gini', efeatset,model)\n",
    "    elif model == 'Random Forest':\n",
    "        RFtrain_test_1(px_impg, yall, featset,'feataccdict', 'gini',efeatset)\n",
    "    \n",
    "    return new_si, sfn_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafa7c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Gini all ethnicities\n",
    "new_si, sfn_list = BestGini_1(Xall,yall, 'Gini features with all ethnicities', Xall, yall,'All ethnicities')\n",
    "sns.set(rc={'figure.figsize':(100,50)})\n",
    "sns.set(font_scale=4)\n",
    "bp = sns.barplot(x = new_si, y = sfn_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf1072f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Gini white only\n",
    "new_si, sfn_list =BestGini_1(Xwhite,ywhite, 'Gini features with only white', Xall, yall,'White')\n",
    "sns.set(rc={'figure.figsize':(100,50)})\n",
    "sns.set(font_scale=4)\n",
    "bp = sns.barplot(x = new_si, y = sfn_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b52987",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Gini black only\n",
    "new_si, sfn_list =BestGini_1(Xblack,yblack, 'Gini features with only black', Xall, yall,'Black')\n",
    "sns.set(rc={'figure.figsize':(100,50)})\n",
    "sns.set(font_scale=4)\n",
    "bp = sns.barplot(x = new_si, y = sfn_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c7c6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Gini asian only\n",
    "new_si, sfn_list =BestGini_1(Xasian,yasian, 'Gini features with only asian', Xall, yall,'Asian')\n",
    "sns.set(rc={'figure.figsize':(100,50)})\n",
    "sns.set(font_scale=4)\n",
    "bp = sns.barplot(x = new_si, y = sfn_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c139d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Gini hispanic only\n",
    "new_si, sfn_list =BestGini_1(Xhispanic, yhispanic, 'Gini features with only hispanic', Xall, yall,'Hispanic')\n",
    "sns.set(rc={'figure.figsize':(100,50)})\n",
    "sns.set(font_scale=4)\n",
    "bp = sns.barplot(x = new_si, y = sfn_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7373469e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "alleth = pd.DataFrame(dict([ (k,pd.Series(v)) for k,v in feataccdict.items() ]))\n",
    "ginidf = alleth[[\"Gini features all ethnicities accuracy\",\"Gini features white only accuracy\", \"Gini features black only accuracy\", \"Gini features asian only accuracy\", \"Gini features hispanic only accuracy\"]]\n",
    "display(ginidf)\n",
    "display(alleth)\n",
    "\n",
    "fig = sns.boxplot(data=ginidf)\n",
    "sns.set(rc={'figure.figsize':(100,50)})\n",
    "sns.set(font_scale=4)\n",
    "plt.xlabel(\"All features\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Gini Feature Accuracy\")\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b621771a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BestGini_1(Xall,yall, 'Gini features with all ethnicities', Xall, yall, 'All ethnicities','Logistic Regression')\n",
    "BestGini_1(Xwhite,ywhite, 'Gini features with only white', Xall, yall, 'White','Logistic Regression')\n",
    "BestGini_1(Xblack,yblack, 'Gini features with only black', Xall, yall, 'Black','Logistic Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad1b0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "BestGini_1(Xasian,yasian, 'Gini features with only asian', Xall, yall, 'Asian','Logistic Regression')\n",
    "BestGini_1(Xhispanic, yhispanic, 'Gini features with only hispanic', Xall, yall, 'Hispanic','Logistic Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ff161c",
   "metadata": {},
   "outputs": [],
   "source": [
    "BestGini_1(Xall,yall, 'Gini features with all ethnicities', Xall, yall, 'All ethnicities','SVM')\n",
    "BestGini_1(Xwhite,ywhite, 'Gini features with only white', Xall, yall, 'White','SVM')\n",
    "BestGini_1(Xblack,yblack, 'Gini features with only black', Xall, yall, 'Black','SVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36423bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "BestGini_1(Xasian,yasian, 'Gini features with only asian', Xall, yall, 'Asian','SVM')\n",
    "BestGini_1(Xhispanic, yhispanic, 'Gini features with only hispanic', Xall, yall, 'Hispanic','SVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0dff01",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#pivot table\n",
    "table = pd.pivot_table(dfalltandf, values='Value', index=['Feature Test'],\n",
    "                    columns=['Features'], aggfunc=np.sum, fill_value=0)\n",
    "display(table)\n",
    "table.to_csv('Allfeatures_AllTests.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03e1ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_palette = sns.color_palette(\"light:b\", as_cmap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a1213c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combines all ftest features and ethnicities to make graph\n",
    "\n",
    "filelist = ['Feature_Sets/Ftest features with all ethnicities.csv', 'Feature_Sets/Ftest features with only asian.csv', \n",
    "            'Feature_Sets/Ftest features with only black.csv', 'Feature_Sets/Ftest features with only white.csv', \n",
    "            'Feature_Sets/Ftest features with only hispanic.csv']\n",
    "ethlist = ['All Ethnicities', 'Asian', 'Black', 'White', 'Hispanic']\n",
    "topnum = 50\n",
    "counter = 0\n",
    "combined_df = pd.DataFrame()\n",
    "\n",
    "for file in filelist:\n",
    "    dfread = pd.read_csv(file)\n",
    "    dfread['Ethnicity'] = ethlist[counter]\n",
    "    sorted_df = dfread.sort_values('F-score', ascending=False).head(topnum)\n",
    "    counter = counter+1\n",
    "    #display(sorted_df)\n",
    "    combined_df = combined_df.append(sorted_df, ignore_index=True)\n",
    "\n",
    "display(combined_df)\n",
    "\n",
    "pivotftest = pd.pivot_table(combined_df, values='F-score', index=['Feature Name'],\n",
    "                    columns=['Ethnicity'], aggfunc=np.sum, fill_value=0)\n",
    "#pivotftest = pivotftest.sort_values('Feature Name', key=lambda x: x.str.lower())\n",
    "display(pivotftest)\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "ax = sns.heatmap(pivotftest,fmt='.0f', annot_kws={'fontsize': 8}, cmap = my_palette)\n",
    "ax.set_yticklabels(labels=ax.get_yticklabels(), va='center')\n",
    "plt.title('F-Test Feature Importance', fontsize=15)\n",
    "plt.xlabel('Ethnicity', fontsize=15)\n",
    "plt.ylabel('Feature Name', fontsize=15)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=10)\n",
    "cbar = ax.collections[0].colorbar\n",
    "cbar.ax.tick_params(labelsize=15)\n",
    "unique_values = combined_df['Feature Name'].unique()\n",
    "print(len(unique_values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8e5226",
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist = ['Feature_Sets/Correlated PBtest features with all ethnicities.csv', 'Feature_Sets/Correlated PBtest features with asian only.csv', \n",
    "            'Feature_Sets/Correlated PBtest features with black only.csv', 'Feature_Sets/Correlated PBtest features with white only.csv', \n",
    "            'Feature_Sets/Correlated PBtest features with hispanic only.csv']\n",
    "ethlist = ['All Ethnicities', 'Asian', 'Black', 'White', 'Hispanic']\n",
    "topnum = 50\n",
    "counter = 0\n",
    "combined_df = pd.DataFrame()\n",
    "\n",
    "for file in filelist:\n",
    "    dfread = pd.read_csv(file)\n",
    "    dfread['Ethnicity'] = ethlist[counter]\n",
    "    sorted_df = dfread.sort_values('Correlation Coefficient', ascending=False).head(topnum)\n",
    "    counter = counter+1\n",
    "    #display(sorted_df)\n",
    "    combined_df = combined_df.append(sorted_df, ignore_index=True)\n",
    "\n",
    "display(combined_df)\n",
    "\n",
    "pivotpbcorr = pd.pivot_table(combined_df, values='Correlation Coefficient', index=['Feature Name'],\n",
    "                    columns=['Ethnicity'], aggfunc=np.sum, fill_value=0)\n",
    "#pivotpbcorr = pivotpbcorr.sort_values('Feature Name', key=lambda x: x.str.lower())\n",
    "display(pivotpbcorr)\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "ax = sns.heatmap(pivotpbcorr, fmt='.2f', annot_kws={'fontsize': 8}, cmap = my_palette)\n",
    "ax.set_yticklabels(labels=ax.get_yticklabels(), va='center')\n",
    "ax.set_yticklabels(labels=ax.get_yticklabels(), va='center')\n",
    "plt.title('Correlated Point Biserial Feature Importance', fontsize=15)\n",
    "plt.xlabel('Ethnicity', fontsize=15)\n",
    "plt.ylabel('Feature Name', fontsize=15)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=10)\n",
    "cbar = ax.collections[0].colorbar\n",
    "cbar.ax.tick_params(labelsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7cdc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist = ['Feature_Sets/Significant PBtest features with all ethnicities.csv', 'Feature_Sets/Significant PBtest features with asian only.csv', \n",
    "            'Feature_Sets/Significant PBtest features with black only.csv', 'Feature_Sets/Significant PBtest features with white only.csv', \n",
    "            'Feature_Sets/Significant PBtest features with hispanic only.csv']\n",
    "ethlist = ['All Ethnicities', 'Asian', 'Black', 'White', 'Hispanic']\n",
    "topnum = 50\n",
    "counter = 0\n",
    "combined_df = pd.DataFrame()\n",
    "\n",
    "for file in filelist:\n",
    "    dfread = pd.read_csv(file)\n",
    "    dfread['Ethnicity'] = ethlist[counter]\n",
    "    sorted_df = dfread.sort_values('P-value', ascending=True).head(topnum)\n",
    "    counter = counter+1\n",
    "    #display(sorted_df)\n",
    "    combined_df = combined_df.append(sorted_df, ignore_index=True)\n",
    "\n",
    "display(combined_df)\n",
    "\n",
    "pivotpbsig = pd.pivot_table(combined_df, values='P-value', index=['Feature Name'],\n",
    "                    columns=['Ethnicity'], aggfunc=np.sum, fill_value=0)\n",
    "#pivotpbsig = pivotpbsig.sort_values('Feature Name', key=lambda x: x.str.lower())\n",
    "pivotpbsig = pivotpbsig.applymap(lambda x: -np.log2(x) if x > 0 else 0)\n",
    "display(pivotpbsig)\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "ax = sns.heatmap(pivotpbsig, fmt='.2f', annot_kws={'fontsize': 8}, cmap = my_palette)\n",
    "ax.set_yticklabels(labels=ax.get_yticklabels(), va='center')\n",
    "plt.title('Significant Point Biserial Feature Importance', fontsize=15)\n",
    "plt.xlabel('Ethnicity', fontsize=15)\n",
    "plt.ylabel('Feature Name', fontsize=15)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=10)\n",
    "cbar = ax.collections[0].colorbar\n",
    "cbar.ax.tick_params(labelsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a973095f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist = ['Feature_Sets/Ttest features with all ethnicities.csv', 'Feature_Sets/Ttest features with asian only.csv', \n",
    "            'Feature_Sets/Ttest features with black only.csv', 'Feature_Sets/Ttest features with white only.csv', \n",
    "            'Feature_Sets/Ttest features with hispanic only.csv']\n",
    "ethlist = ['All Ethnicities', 'Asian', 'Black', 'White', 'Hispanic']\n",
    "topnum = 20\n",
    "counter = 0\n",
    "combined_df = pd.DataFrame()\n",
    "\n",
    "for file in filelist:\n",
    "    dfread = pd.read_csv(file)\n",
    "    dfread['Ethnicity'] = ethlist[counter]\n",
    "    sorted_df = dfread.sort_values('P-value', ascending=True).head(topnum)\n",
    "    counter = counter+1\n",
    "    #display(sorted_df)\n",
    "    combined_df = combined_df.append(sorted_df, ignore_index=True)\n",
    "\n",
    "display(combined_df)\n",
    "\n",
    "pivotttest = pd.pivot_table(combined_df, values='P-value', index=['Feature Name'],\n",
    "                    columns=['Ethnicity'], aggfunc=np.sum, fill_value=0)\n",
    "#pivotttest = pivotttest.sort_values('Feature Name', key=lambda x: x.str.lower())\n",
    "pivotttest = pivotttest.applymap(lambda x: -np.log2(x) if x > 0 else 0)\n",
    "display(pivotttest)\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "ax = sns.heatmap(pivotttest, fmt='.2f', annot_kws={'fontsize': 8}, cmap = my_palette)\n",
    "ax.set_yticklabels(labels=ax.get_yticklabels(), va='center')\n",
    "plt.title('T-Test Feature Importance', fontsize=15)\n",
    "plt.xlabel('Ethnicity', fontsize=15)\n",
    "plt.ylabel('Feature Name', fontsize=15)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=10)\n",
    "cbar = ax.collections[0].colorbar\n",
    "cbar.ax.tick_params(labelsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22e42c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist = ['Feature_Sets/Gini features with all ethnicities.csv', 'Feature_Sets/Gini features with only asian.csv', \n",
    "            'Feature_Sets/Gini features with only black.csv', 'Feature_Sets/Gini features with only white.csv', \n",
    "            'Feature_Sets/Gini features with only hispanic.csv']\n",
    "ethlist = ['All Ethnicities', 'Asian', 'Black', 'White', 'Hispanic']\n",
    "topnum = 50\n",
    "counter = 0\n",
    "combined_df = pd.DataFrame()\n",
    "\n",
    "for file in filelist:\n",
    "    dfread = pd.read_csv(file)\n",
    "    dfread['Ethnicity'] = ethlist[counter]\n",
    "    sorted_df = dfread.sort_values('Gini score', ascending=False).head(topnum)\n",
    "    counter = counter+1\n",
    "    #display(sorted_df)\n",
    "    combined_df = combined_df.append(sorted_df, ignore_index=True)\n",
    "\n",
    "display(combined_df)\n",
    "\n",
    "pivotgini = pd.pivot_table(combined_df, values='Gini score', index=['Feature Name'],\n",
    "                    columns=['Ethnicity'], aggfunc=np.sum, fill_value=0)\n",
    "#pivotgini = pivotgini.sort_values('Feature Name', key=lambda x: x.str.lower())\n",
    "display(pivotgini)\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "ax = sns.heatmap(pivotgini, fmt='.2f', annot_kws={'fontsize': 8}, cmap = my_palette)\n",
    "ax.set_yticklabels(labels=ax.get_yticklabels(), va='center')\n",
    "plt.title('Gini Impurity Feature Importance', fontsize=15)\n",
    "plt.xlabel('Ethnicity', fontsize=15)\n",
    "plt.ylabel('Feature Name', fontsize=15)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=10)\n",
    "cbar = ax.collections[0].colorbar\n",
    "cbar.ax.tick_params(labelsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ededb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_PR_curve(outdf, save_to_filename, testname):\n",
    "    #ytrue = np.concatenate(y_true)\n",
    "    #proba = np.concatenate(y_proba)\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    groups = outdf.groupby('Race') \n",
    "\n",
    "    i = 0\n",
    "    for name, grp in groups:\n",
    "        #print(name)\n",
    "        #display(grp)\n",
    "        y_true = grp['y_true']\n",
    "        y_proba = grp['probs']\n",
    "        colors = ['blue' ,'green', 'orange', 'red','yellow']\n",
    "        \n",
    "        ap_score = average_precision_score(y_true, y_proba)\n",
    "        \n",
    "        mean_recall = np.linspace(0,1,100)\n",
    "        precision,recall, _ = precision_recall_curve(y_true, y_proba)\n",
    "        precision = np.interp(mean_recall,precision,recall)\n",
    "        \n",
    "        label = '%s AP=%.4f' % (str(name), ap_score)\n",
    "                                                    \n",
    "        ax.plot(\n",
    "                mean_recall,\n",
    "                precision,\n",
    "                label=label,\n",
    "                lw=1,\n",
    "                color=colors[i])   \n",
    "        i = i+1\n",
    "        \n",
    "    ax.set(\n",
    "    xlim=[-0.05, 1.05],\n",
    "    ylim=[-0.05, 1.05],\n",
    "    xlabel='Recall',\n",
    "    ylabel='Precision',\n",
    "    title=testname)  \n",
    "        \n",
    "    #ax.set_xlabel('Recall', fontsize=10)\n",
    "    #ax.set_ylabel('Precision', fontsize=10)\n",
    "    #ax.set_title(testname, fontsize=15, pad=10)\n",
    "    ax.legend(loc=\"lower right\", fontsize=10)\n",
    "\n",
    "    plt.style.use('default')\n",
    "    ax.legend(loc=\"lower right\")\n",
    "    plt.savefig(save_to_filename)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b2f988",
   "metadata": {},
   "outputs": [],
   "source": [
    "#precision recall curve\n",
    "#from EXPERIMENTS_WITH_PROBS import plot_PR_curve\n",
    "filelist = [proballfeat, probftest, probttest, probsigpb, probcorrpb, probgini]\n",
    "testname = ['All Features Precision-recall curve', 'F-Test Precision-recall curve',\n",
    "            'T-Test Precision-recall curve', 'Signficant Point Biserial Precision-recall curve', \n",
    "            'Correlated Point Biserial Precision-recall curve', 'Gini Impurity Precision-recall curve']\n",
    "\n",
    "x = 0 \n",
    "for file in filelist:\n",
    "    dfread = pd.read_csv(file)\n",
    "    #display(dfread)\n",
    "    #display(dfread['y_true'])\n",
    "    #display(dfread['probs'])\n",
    "    #ytrue = np.concatenate([dfread['y_true']])\n",
    "    #proba = np.concatenate([dfread['probs']])\n",
    "    newfile = file.replace(\"csv\", \"png\")\n",
    "    plot_PR_curve(dfread, prcurvedirectory+'/PRcurve_'+newfile, testname[x])\n",
    "    x = x+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38482c9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b43123",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BVfeatenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "8faf36a0d774d735f6aa6cd95382c4427e3075a1258133a11592512e17048d96"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
